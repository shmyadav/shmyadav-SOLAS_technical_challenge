{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6oRKIGRTb-v",
    "outputId": "4ce5ef6b-6998-4e37-88db-f999e3e800ec"
   },
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install openai\n",
    "# !pip install pinecone\n",
    "# !pip install pinecone-client\n",
    "# !pip install tiktoken\n",
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpQWAbRyMQKe"
   },
   "source": [
    "# Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0cf9f13",
    "outputId": "f32e6c27-2e37-4233-cd96-fdd254289b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY={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}\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY={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}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53b711f1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRKoNwHqk-K1",
    "outputId": "17624df3-e73b-4858-8b8c-ac44327fba90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3e7a8c9"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/maritime/SOLAS_technical_challenge.txt\",\"r\") as fl:\n",
    "    a = fl.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03b75c15",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "chunks = re.split(r'\\n\\n', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bdb8a68"
   },
   "outputs": [],
   "source": [
    "chunks = [re.sub(r'\\n+CSV TABLE:', ' ', i) for i in chunks]\n",
    "chunks = [re.sub(r'CSV TABLE:\\n+', ' ', i) for i in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b97e2af3"
   },
   "outputs": [],
   "source": [
    "chunks = [i.replace(\"CSV TABLE:\",\"\") for i in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b99a8701"
   },
   "outputs": [],
   "source": [
    "chunks = [i.strip().splitlines() for i in chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da604088"
   },
   "source": [
    "### If len(y) ==3: Topic Description Content </br> if len(y) < 2 Description missing </br> if len(y) > 3 Topic Description mrege rest to Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebcf98f7"
   },
   "outputs": [],
   "source": [
    "def organiser(x):\n",
    "    if len(x) == 3:\n",
    "        return \"\"\"Topic: {} \\nDescription : {}\\nContent: {}\"\"\".format(x[0],x[1],x[2])\n",
    "    if len(x)<3:\n",
    "        try:\n",
    "            return \"\"\"Topic: {}\\nContent: {}\"\"\".format(x[0],x[1])\n",
    "        except:\n",
    "            print(x)\n",
    "            try:\n",
    "              return \"\"\"content: {}\"\"\".format(x[0])\n",
    "            except: return \"\"\n",
    "    if len(x)>3:\n",
    "        z = \"\"\n",
    "        for i in range(len(x)):\n",
    "            if i < 2:\n",
    "                #y.append(x[i])\n",
    "                pass\n",
    "            else:\n",
    "                z = z + \" \" + x[i]\n",
    "        return \"\"\"Topic: {}\\nDescription : {}\\nContent: {}\"\"\".format(x[0],x[1],z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91066d48",
    "outputId": "4b2851aa-a83b-481a-c318-1c1bdc53e70f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "y = [organiser(i) for i in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kfnavN14lERo"
   },
   "outputs": [],
   "source": [
    "for i  in range(len(y)):\n",
    "  file = \"/content/drive/MyDrive/maritime/multiDoc/{}.txt\".format(i)\n",
    "  with open(file,\"w\") as fl:\n",
    "    fl.write(y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "kmvLPJU9BPaf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain import VectorDBQA, OpenAI\n",
    "import pinecone\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "I_GnQvdwG-nN"
   },
   "outputs": [],
   "source": [
    "# Load and process the text files\n",
    "# loader = TextLoader('single_text_file.txt')\n",
    "loader = DirectoryLoader('/content/drive/MyDrive/maritime/multiDoc', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wj1VFQbSxvIL"
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# a = re.sub(r'\\n\\n',\"septoken\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-7iCLHoyk0h"
   },
   "outputs": [],
   "source": [
    "# with open(\"/content/drive/MyDrive/maritime/SOLAS_technical_challenge.txt\",\"w\") as fl:\n",
    "#     fl.write(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "sGYCUSy-HJ9y"
   },
   "outputs": [],
   "source": [
    "# print(\"Hello VectorStore!\")\n",
    "# loader = TextLoader(\n",
    "#     \"/content/drive/MyDrive/maritime/SOLAS_technical_challenge.txt\"\n",
    "# )\n",
    "# document = loader.load()\n",
    "\n",
    "# text_splitter = CharacterTextSplitter(separator = \"septoken\",chunk_size=2000, chunk_overlap=100,is_separator_regex=False)\n",
    "\n",
    "# texts = text_splitter.split_documents(document)\n",
    "\n",
    "#splitting the text into\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FHDZcS2sZjMd",
    "outputId": "c40efdb0-6f13-494c-aee2-31035e2a89e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY={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}\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY={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}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "o_OqcdllHRIe"
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=\"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\",)\n",
    "# docsearch = Pinecone.from_documents(\n",
    "#     texts, embeddings, index_name=\"maritime\"\n",
    "# )\n",
    "# load it into Chroma\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "l0dIF1fYo6Tv"
   },
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "UESjLmEBpFpj"
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"\"\"For a passenger ship of 2000 GT, do I need to install the VDR?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44vXDzG_G8gU",
    "outputId": "ff71426f-ac2c-44e0-90de-1f9d42e12657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Topic: ARTICLE V \\nDescription : Carriage of persons in emergencies\\nContent: (a) For the purpose of evacuating persons in order to avoid a threat to the security of their lives a Contracting Government may permit the carriage of a larger number of persons in its ships than is otherwise permissible under the present Convention. (b) Such permission shall not deprive other Contracting Governments of any right of control under the present Convention over such ships which come within their ports. (c) Notice of any such permission, together with a statement of the circumstances, shall be sent to the Secretary-General of the Organization by the Contracting Government granting such permission.' metadata={'source': '/content/drive/MyDrive/maritime/multiDoc/5.txt'}\n"
     ]
    }
   ],
   "source": [
    "# query it\n",
    "query = \"\"\"Which is the total overall clear height for vehicles in special category spaces?\"\"\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "# print results\n",
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "c9IImxY_4NkN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "s2j2IfJyq23Z"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "z2GDYctFq20l"
   },
   "outputs": [],
   "source": [
    "# create the chain to answer questions\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo-16k',openai_api_key=\"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\"),\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "WCdYktyJq2yM"
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21tbmMhCq2nI",
    "outputId": "7cd080db-e0dd-4ee0-c428-897798c1440a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, on passenger ships constructed on or after 1 July 2008, non-load bearing partial bulkheads which separate adjacent cabin balconies shall be capable of being opened by the crew from each side for the purpose of fighting fires. This means that there should be some fire protection measures in place for cabin balconies on cruise vessels.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/drive/MyDrive/maritime/multiDoc/139.txt\n",
      "/content/drive/MyDrive/maritime/multiDoc/139.txt\n",
      "/content/drive/MyDrive/maritime/multiDoc/138.txt\n",
      "/content/drive/MyDrive/maritime/multiDoc/138.txt\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"\"\"Do I need any fire protection on the cabin balconies of a cruise vessel?\"\"\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTF4h1d62dyE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
